{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advances in Machine Learning with Big Data\n",
    "\n",
    "### Trinity 2021\n",
    "### Jeremy Large\n",
    "#### jeremy.large@economics.ox.ac.uk\n",
    "\n",
    "\n",
    "&#169; Jeremy Large ; shared under [CC BY-NC-ND 4.0](https://creativecommons.org/licenses/by-nc-nd/4.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 11. Introductory remarks on Causal Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Contents Weeks 1-7:\n",
    "\n",
    "1. Introducing this course's dataset\n",
    "\n",
    "1. Being an econometrician _and_ a data scientist\n",
    "\n",
    "1. Overfit and regularization\n",
    "\n",
    "1. Regularization through predictor/feature selection (Lasso etc.)\n",
    "\n",
    "1. Resampling methods, and model selection\n",
    "\n",
    "1. Classification\n",
    "\n",
    "1. Decision trees, bagging, and random forests\n",
    "\n",
    "1. Make a start on neural networks\n",
    "\n",
    "1. Convolutional neural nets and image classification (Lucas Kruitwagen)\n",
    "\n",
    "1. Transfer learning (Lucas Kruitwagen)\n",
    "\n",
    "1. **Causal inference**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The relationship between machine learning and empirical economics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Judea Pearl (~2018): [\"All the impressive achievements of deep learning amount to just curve fitting\"](https://www.theatlantic.com/technology/archive/2018/05/machine-learning-is-stuck-on-asking-why/560675/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "He's deprecating the activity of predicting, and he certainly has a point:\n",
    "\n",
    "Prediction may be interesting for observers, speculators, but ...\n",
    "\n",
    "... for action, including policy and law, we need to understand causes and effects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Often, we want causation, not correlations,\n",
    "    \n",
    "* so we want to do Causal Inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Interestingly, Pearl is not quite in agreement with mainstream econometricians about how to formulate CI:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Imbens (2020)](https://arxiv.org/pdf/1907.07271.pdf) outlines the fault-lines\n",
    "\n",
    "> *Potential Outcome and Directed Acyclic Graph Approaches to Causality: Relevance for Empirical Practice in Economics*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "A comprehensive, recent, overview of ML and empirical economics is in [Athey and Imbens (2019)](https://arxiv.org/pdf/1903.10075.pdf).\n",
    "\n",
    "* strong emphasis on causation (esp. Section 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### **Manipulability** and the meaning of 'cause'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Widespread agreement on the centrality of 'manipulation' in causal theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Kids play/experiment -> discover their ability to affect the world -> discover they can cause changes in the world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "They watch other kids play and learn cause/effect by watching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Adults (we) inherit the same way of thinking:\n",
    "* sometimes we experiment ourselves (Randomised Control Trials / AB Trials);\n",
    "* sometimes we watch others experiment;\n",
    "* sometimes we watch a natural experiment ('observational study')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Policy-makers, econometricians and statisticians do the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We often have to make-do with observational study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Recall: supervised learning**: an i.i.d. sequence of observations, $\\{(Y_i, X_i), i=0, 1, ...\\}$. There is a distribution of the R.V. $Y_i$, conditional on the stacked regressors, namely $X$:\n",
    "\\begin{equation}\n",
    "Y_i | X \\ \\ \\sim \\ \\ \\mathcal f_{X_i; \\theta},\n",
    "\\end{equation}\n",
    "\n",
    "where the $\\theta$ stands-in for our parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "NB: Just because we might predict $Y_i$ from $X_i$ in test data, this does not mean that $X_i$ causes $Y_i$.\n",
    "* they could share a common cause (a confounder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* so we need to add at least a third random variable to our mix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* we'll let $X_i$ do the job of 'common cause / confounder'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ... and we'll add a *treatment* variable, $W_i$, that might affect our *outcome*, $Y_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Call the treatment $W_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "So we see an i.i.d. sequence of 'observational data', $\\{(Y_i, X_i, W_i), i=0, 1, ...\\}$. The treatment, $W_i$, can be 0 or 1; 'absent' or 'present'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Crucial idea is that, unlike $Y_i$ and $X_i$, \n",
    "* $W_i$ is special, because (even though we often simply see it), sometimes we can *also* ... \n",
    "\\begin{equation*}\n",
    "do(W_i)\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* When we $do(W_i)$ we **break the correlation** between $W_i$ and its usual causes (namely, here, $X_i$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is a random variable where we can intervene and act! Pearl's [do-calculus](https://en.wikipedia.org/wiki/Causal_model#Do_calculushttps://en.wikipedia.org/wiki/Causal_model#Do_calculus)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "When we $do(W_i=0)$, there is a distribution of the R.V. $Y_i$, conditional on the stacked regressors, namely $X$:\n",
    "\\begin{equation*}\n",
    "Y_i(0) | X \\ \\ \\sim \\ \\ \\mathcal f^0_{X_i; \\theta},\n",
    "\\end{equation*}\n",
    "Similarly, when we $do(W_i=1)$,\n",
    "\\begin{equation*}\n",
    "Y_i(1) | X \\ \\ \\sim \\ \\ \\mathcal f^1_{X_i; \\theta},\n",
    "\\end{equation*}\n",
    "\n",
    "where the $\\theta$ stands-in for our parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "And **if the treatment has an effect, then**:\n",
    "\\begin{equation*}\n",
    "\\mathcal f^1_{X_i; \\theta} \\ \\ \\neq \\ \\ \\mathcal f^0_{X_i; \\theta}.\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Treatment Effects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**ITE**  : $Y_i(1) - Y_i(0)$\n",
    " * individual treatment effect\n",
    " * unknowable! - we never see both parts\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**ATE**  : $E[Y_i(1) - Y_i(0)]$\n",
    " * average treatment effect\n",
    " * a significant objective in science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Important point: in general,\n",
    "\\begin{equation*}\n",
    "E[Y_i(1) - Y_i(0)] \\ \\ \\neq \\ \\ E[Y_i| W_i=1] - E[Y_i | W_i=0],\n",
    "\\end{equation*}\n",
    "because, begin good Bayesians, we get *backdoor* information about $X_i$ from $W_i$, and that information pertains to $Y_i$ as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "... unless, that is, $\\{W_i\\}$ is being generated in a randomized trial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sufficient Adjustment Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Important point: in general,\n",
    "\\begin{equation*}\n",
    "E[Y_i(1) - Y_i(0)] \\ \\ \\neq \\ \\ E[Y_i| W=1] - E[Y_i | W=0]\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "However, if $X$ contains enough confounding variables, then:\n",
    "\\begin{equation*}\n",
    "E[Y_i| do(W_i=w), X_i] \\ \\ = \\ \\ E[Y_i|W_i=w, X_i],\n",
    "\\end{equation*}\n",
    "so that, using the Law of Iterated Expectations,\n",
    "\\begin{equation*}\n",
    "E[Y_i(w)] \\ \\ = \\ \\ E_X\\left[ E[Y_i|W_i=w, X_i] \\right],\n",
    "\\end{equation*}\n",
    "and we can use this to calculate the ATE of $W_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If $X$ has this property, then we say that $X$ is a *sufficient adjustment set*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "> The case of estimating average treatment effects under unconfoundedness is an example of a more general theme from econometrics; typically, economists prioritize **precise estimates of causal effects** above **predictive power** ([Athey and Imbens (2019)](https://arxiv.org/pdf/1903.10075.pdf))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
